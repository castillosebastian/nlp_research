{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/castillosebastian/nlp_research/blob/master/BETO_examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhAqZLs3lwhW"
      },
      "source": [
        "# Fist install the library and download the models from github\n",
        "\n",
        "!pip install transformers\n",
        "!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/pytorch_weights.tar.gz \n",
        "!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/vocab.txt \n",
        "!wget https://users.dcc.uchile.cl/~jperez/beto/cased_2M/config.json \n",
        "!tar -xzvf pytorch_weights.tar.gz\n",
        "!mv config.json pytorch/.\n",
        "!mv vocab.txt pytorch/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_1ucCCUnXqa"
      },
      "source": [
        "# import the necessary\n",
        "\n",
        "import torch\n",
        "from transformers import BertForMaskedLM, BertTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCpOxoXkoGFC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3f7c9d-8100-4ae1-cb1b-c4737af709a6"
      },
      "source": [
        "# create the tokenizer and the model\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"pytorch/\", do_lower_case=False)\n",
        "model = BertForMaskedLM.from_pretrained(\"pytorch/\")\n",
        "e = model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at pytorch/ were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KXo6-ahoJoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8ac41e-8c6a-4a74-bb62-84d5b8368208"
      },
      "source": [
        "# Now test it\n",
        "\n",
        "text = \"[CLS] Para solucionar los [MASK] de Chile, el presidente debe [MASK] de inmediato. [SEP]\"\n",
        "masked_indxs = (4,11)\n",
        "\n",
        "tokens = tokenizer.tokenize(text)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "predictions = model(tokens_tensor)[0]\n",
        "\n",
        "for i,midx in enumerate(masked_indxs):\n",
        "    idxs = torch.argsort(predictions[0,midx], descending=True)\n",
        "    predicted_token = tokenizer.convert_ids_to_tokens(idxs[:5])\n",
        "    print('MASK',i,':',predicted_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MASK 0 : ['problemas', 'conflictos', 'asuntos', 'males', 'temas']\n",
            "MASK 1 : ['renunciar', 'actuar', 'intervenir', 'regresar', 'asumir']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb9CZLSgQphw"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
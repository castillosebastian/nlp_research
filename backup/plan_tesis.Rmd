---
title: "Detección de entidades nombradas en textos legales"
author: "Claudio Sebastián Castillo"
date: "2022-11-03"
output: pdf_document
bibliography: nlp_ner.bib  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Tema elegido

En este documento presentamos nuestro Plan de Tesis para la Maestría en Minería de Datos de la UTN -Regional Paraná- en el marco del área de Procesamiento del Lenguaje Natural (NLP), en el tópico vinculado a reconocimiento de entidades nombradas (NER). El objetivo del trabajo es implementar algoritmos de aprendizaje automático orientados a reconocer y extraer información de textos legales. El dominio legal es un campo de producción de grandes volúmenes de información textual, cuyo contenido y alcance impacta de manera definitiva en la vida de muchas personas. Esta información es eminentemente no estructurada por lo que su exploración y explotación enfrenta grandes desafíos. Hasta donde conocemos, en nuestro país no existen experiencias publicadas de explotación de los atributos lingüísticos del texto en el dominio legal. Por todo ello, en este trabajo nos proponemos implementar en este ámbito los algoritmos que hayan acreditado los mejores resultados en la tarea de reconocimiento de entidades nombradas. Para ello vamos a: 1) construir un corpus legal que nos permita probar distintas soluciones para la tarea de reconocimiento y anotación de entidades, y 2) desarrollar *nuevas implementaciones* de algoritmos de aprendizaje para el tratamiento de dicho corpus buscando las configuraciones con mejor performance.

# Fundamentación y justificación del tema

El reconocimiento y la clasificación de entidades nombradas (en adelante NER/NERC por las siglas en inglés *Named Entity Recoginition and Classification*) es una de las tareas más comunes[@vajjala2022] dentro del Procesamiento del Lenguaje Natural (en adelante NLP o *tecnologías del lenguaje*[^1]). Normalmente consiste en la identificación automática -sin intervención humana- de entidades nombradas en textos[^2] y su asignación a determinadas categorías semánticas. Estas unidades refieren generalmente a entidades que puede aludirse mediante *nombres propios* -e.g. personas, organizaciones y localizaciones- aunque en la práctica se han extendido para incluir expresiones numéricas referidas a fechas y cantidades, o distintos tipos de entidades que varían según el dominio de interés. Esta referencia a entidades puede consistir en expresiones lingüísticas simples o complejas, confiriendo a la tarea de reconocimiento automático un nivel de dificultad importante [@jurafsky2021].

[^1]: Referencia acuñada por el Gobierno de España y que da el nombre al plan de desarrollo de tecnologías de NLP: *Plan de Impulso de las Tecnologías del Lenguaje*, <https://plantl.mineco.gob.es/tecnologias-lenguaje/PTL/Paginas/plan-impulso-tecnologias-lenguaje.aspx>).

[^2]: A partir de las expresiones lingüísticas que sirven, en una determinada comunidad lingüística, para referenciarlas.

Según @li2020 podemos agrupar las técnicas aplicadas en NER en cuatro tipos: 1) enfoques basados en reglas que no necesitan datos anotados porque descansan en la formulación particular de reglas lingüísticas, 2) enfoques basados en aprendizaje no supervisado que emplean algoritmos del mismo tipo (e.g. *clustering*) y tampoco emplean datos anotados, 3) enfoques basados en ingeniería de atributos (o predictores) y aprendizaje supervisado (i.e. como problema de clasificación multiclase)[^3], y 4) enfoques de aprendizaje profundo (e.g. *deep neural networks*) capaces de generar automáticamente la representación óptima de los datos para resolver el problema NER. Estos últimos enfoques han generado un cambio de paradigma en el NLP en general y en las tareas NER en particular gracias a los buenos resultados obtenidos con el uso de redes neuronales profundas (*Deep Neural Networks* o DNN) y la integración de modelos del lenguaje bajo la forma de r*epresentación distribuida* o *representación vectorial* de los datos (*Embeddings* ) [@roy2021].

[^3]: Dentro de este grupo se han empleado distintos algoritmos, entre los que se encuentran: *Hidden Markov Models (HMM), Decision Trees, Maximum Entropy Models, Support Vector Machines (SVM)*, y *Conditional Random Fields (CRF)*.

Este escenario propicio y estimulante en materias de *nuevas tecnologías del lenguaje* impulsa la mirada sobre ámbitos con uso intensivo del soporte textual. Entre ellos el Estado y particularmente el Poder Judicial, representan espacios de una larga historia de procedimientos escritos con hondo impacto en las personas. En efecto, éste último tiene la función constitucional de brindar justicia y al hacerlo velar por el Estado de Derecho y la resolución pacífica de conflictos. Esa tarea fundamental para la vida en comunidad tiene como producto central a la *sentencia judicial*, un tipo de documento textual donde un juez reconstruye una situación problemática y fija la solución jurídica que corresponde. Tan importante es este documento que tiene la fuerza de una ley particular para las personas involucradas en el conflicto y el poder de un mensaje acerca de "lo justo" para toda la sociedad. Por eso Rosatti, juez de la Corte Suprema de Justicia de la Nación, resaltando la importancia del lenguaje, dice que:*"las sentencias deben ser profundas y claras"* porque *"todos deben saber qué está prohibido"* [@rosatti2022].

En efecto, la *sentencia judicial* es un documento público que concentra todos los datos relevantes de una *proceso judicial*, desde referencias a las partes, lugares y fechas de una causa, hasta complejas descripciones de hechos y derechos. Estos elementos se articulan mediante un discurso eminentemente técnico, que procede -a priori- a partir de una argumentación racional de la forma premisas-conclusión. Tales atributos tornan a las *sentencias judiciales* objetos de un valor epistemológico significativo, y a su agregación en bases de datos en potenciales *reservorios* de conocimiento.

Desafortunadamente existe una gran asimetría entre la importancia que tienen las sentencias judiciales como fuente de información y la escasez de desarrollos orientados a explotar sus atributos lingüísticos. Esa asimetría se explica, en gran medida, por la escasez de recursos en general para el NLP en español, y en particular para el español legal. En línea con esto @samy2021 menciona entre los *retos* que enfrentan los proyectos de NLP en el ámbito legal en español a: *1) El número limitado de recursos y herramientas adaptados al dominio;* *2) La predominancia del inglés, ya que la mayoría de los recursos y las herramientas disponibles se desarrollan para el tratamiento de textos en inglés;* y *3) Una adopción ralentizada de las tecnologías inteligentes en el sector legal y administrativo en comparación con otros sectores como el sector biomédico o financiero.* Por su parte @cardellino_low-cost_2017 refuerzan esta enumeración destacando que *existen muy pocos corpus legales anotados con anotaciones para entidades* [lo que ] *constituye una importante barrera para la Extracción de Información.* Dificultades similares destacan @leitner_fine-grained_2019 , @serrano2022, entre otros.

A pesar de esas dificultades, y como mencionamos antes, los últimos años han sido testigos de importantes avances en NLP. Nuevos modelos, con arquitecturas inéditas tendientes a optimizar los procesos de aprendizaje @serrano2022, han logrado mejorar las métricas de evaluación para distintas tareas de análisis semántico, obteniendo resultados que igualan o superan los obtenidos por un hablante nativo promedio. Junto con ese nuevo conocimiento, nuevos proyectos públicos[^4] y privados[^5] con eje en las *tecnologías del lenguaje* han ganado presencia no solo en el campo científico sino también en el discurso público, colocando al NLP como tópico de interés general.

[^4]: En el ámbito del NLP en español se detacan proyectos interinstitucionales de alcance nacional como el Plan de Impulso de las Tecnologías del Lenguaje del Gobierno de España dirigido a fomentar el desarrollo del procesamiento del lenguaje natural y la traducción automática en lengua española y lenguas cooficiales (<https://plantl.mineco.gob.es/tecnologias-lenguaje/PTL/Paginas/plan-impulso-tecnologias-lenguaje.aspx>). A nivel internacional el Proyecto de la Comunidad Europea MIREL (<https://www.mirelproject.eu/>) dirigidos a promover el avance de las *tecnologías del lenguaje,* similiar a *MARCELL ( <https://marcell-project.eu/>*), entre otros.

[^5]: [OpenAI](https://openai.com/), [DeepMind](https://www.deepmind.com/), [Ought](https://ought.org/), [Hugging Face](https://huggingface.co/), [Cohere](https://cohere.ai/), entre una larga lista de proyectos disruptivos. Un artículo que repasa empresas y desarrollos puede consultarse aquí: <https://hbr.org/2022/04/the-power-of-natural-language-processing>.

Por todo esto, el presente Plan de Tesis está dirigido a realizar un aporte al área del NLP en español aplicado al dominio legal, empleando para ello los algoritmos que hayan demostrado mejor performance en estudios comparados. A continuación desarrollaremos el alcance de este proyecto.

# Objetivos

1.  Construir un corpus de textos legales que nos permita probar soluciones para la tarea de reconocimiento y anotación de entidades nombradas, y
2.  Desarrollar los algoritmos más apropiados para el tratamiento de dicho corpus buscando las configuraciones con mejor performance.

# Factibilidad y relevancia

El proyecto que hemos propuesto es factible porque disponemos de los medios científicos y tecnológicos requeridos para su ejecución.

Respecto del conocimiento requerido cabe destacar que el área de investigación en NLP-NER, a pesar de sus jóvenes 30 años, ha visto un acelerado crecimiento en materia de recursos y enfoques disponibles [@roy2021]. Desde las primeras soluciones basadas en modelos lineales y reglas lingüísticas, pasando por modelos híbridos que combinan algo de lo anterior con aprendizaje estadístico, hasta los actuales modelos no-lineales basados en redes neuronales profundas y respresentación distribuida de datos (*word/character embedings*)*,* existe un amplio espectro de enfoques para nutrir nuestros abordajes del problema [@serrano2022].

Aunque estos avances tienen como lenguaje objeto al idioma inglés, no han dejado de impulsar en los últimos años un florecimiento del NLP en español. Gracias a ello, las carencias antes apuntadas han comenzado a revertirse parcialmente [@gutiérrez-fandiño2021][@gutiérrez-fandiño][@serrano2022], ofreciéndonos material de valor para nuestro proyecto cuyo detalle presentaremos en el *estado del arte.*

Respecto de la factibilidad para construir un corpus legal útil para este trabajo tenemos evidencia de las múltiples opciones disponibles. En nuestro experimento de construcción de corpus legal[^6] hemos trabajo con el portal de jurisprudencia del Poder Judicial de la provincia de Buenos Aires que brinda acceso público a fallos judiciales[^7]. En el experimento construimos un dataset no anotado de 4299 sentencias judiciales y sus respectivos metadatos empleando el método de *scraping*. Esta información consta de fallos judiciales completos y metadatos de la causa (materia, tipo de fallo, número de la causa, caratula, magistrado y tribunal actuantes, entre otros), que brindarían los insumos para una anotación parcial de ciertas entidades textuales (e.g. 'magistrados').

[^6]: Accesible en github aquí: <https://github.com/castillosebastian/nlp_research/blob/master/Crear_corpus_judicial_experimento0.ipynb>

[^7]: <https://juba.scba.gov.ar/Busquedas.aspx>

Información similar a la obtenida de la justicia de Buenos Aires se publica por distintos Poderes Judiciales del país. Aunque existen diferencias de formatos y medios de publicación, en general se repiten protocolos de publicación que permitirían disponer de un grupo de datos relativamente estable. Por esto entendemos que existe disponibilidad material y tecnológica para construir el corpus.

Abonando lo anterior, contamos con un ejemplo análogo de construcción de corpus en el trabajo de tesis de grado de Karen Haag bajo la dirección de Cristian Cardellino en la Facultad de Matemática, Astronomía, Física y Computación Universidad Nacional de Córdoba en el año 2019[^8]. El trabajo aborda el mismo tópico que estamos presentando en este documento NLP-NER aplicado al dominio legal, y el corpus empleado fue construido ad-hoc para la tesis mediante *scraping* del portal Infoleg[^9] según se detalla en el punto 3.

[^8]: Accesible aquí <https://rdu.unc.edu.ar/bitstream/handle/11086/15323/Haag%2C%20K.%20Y.%20Reconocimiento%20de%20entidades%20nombradas%20en%20texto%20de%20dominio%20legal.pdf?sequence=1&isAllowed=y>

[^9]: <http://www.infoleg.gob.ar/>

Luego de exponer los argumentos acerca de la factibilidad de proyecto es preciso mencionar las razones que hacen a su relevancia.

En primer lugar, desde una perspectiva estrictamente funcional, el desarrollo de estrategias de NLP-NER aplicadas al dominio legal realizaría un aporte inestimable al procesamiento de información textual. El servicio de justicia se asienta sobre el intercambio de información entre los distintos actores de un proceso: jueces, abogados y auxiliares de justicia. Ello sin mencionar la red de instituciones públicas que interactuan permanentemente en la materialización de los actos de servicio (i.e. Registros Públicos, Colegios Profesionales, Instituciones de Salud Pública y Asistenciales, entre otras). Este ecosistema genera documentos que se agregan a un registro de base de datos y componen la historia de un proceso. Estos registros, que conforman un *expediente digital*, actualmente alimentan grandes bases documentales cuya explotación lingüística es incipiente. Contar con herramientas de NLP-NER aplicados al ámbito legal permitiría desarrollar nuevos productos y servicios para las distintas partes interesadas, al tiempo que optimizaría los recursos disponibles en los Poderes Judiciales [@leitner_fine-grained_2019]. Por ejemplo, proyectos vinculados a gestión electrónica, celeridad de procesos, regulación de flujos de información y trabajo[^10] se podrían beneficiar drásticamente con el desarrollo de sistemas inteligentes que permitan extraer y procesar atributos lingüísticos de los documentos legales [@samy2021].

[^10]: Desarrollos que en las instituciones de justicia adquieren cada vez mayor visibilidad e importancia - ver Soto, Andres, *Nuevas Tecnologías y Gerenciamiento de la Ofician Judicial,* publicado en *Nueva gestión judicial : oralidad en los procesos civiles,* Héctor M. Chayer [et al.] , CABA, Ediciones SAIJ, 2017.

En segundo lugar, desde una perspectiva institucional, el desarrollo de procesos internos sensibles a los atributos lingüísticos del texto liberaría posibilidades de automatización sin precedentes, elevando la calidad del servicio de justicia que se brinda al ciudadano. En efecto, los grandes procesos de reforma procesal de los últimos años -tendientes a oralizar los procesos judiciales- han establecido deberes de actuación exigentes a los órganos de justicia. Principios como la *oficiocidad, celeridad, concentración, economía procesal* y *plazo razonable* [^11] demandan una capacidad de procesamiento de la información capaz de reconocer, clasificar, ordenar y distribuir información textual no estructurada de manera robusta y eficiente. [^12] Este escenario es un espacio fértil para el desarrollo de las *tecnologías del lenguaje* que estudiaremos en este proyecto, tecnologías que ya están generando profundos cambios en otras esferas de la vida social.

[^11]: El Tribunal Superior de Justicia de la Provincia de Córdoba, mediante Ac. Reg. N° 1550 Serie "A" de fecha 19/02/2019 aprobó el "Protocolo de gestión del Proceso Civil Oral", que enuncia y explica aquellos principios. Ideas rectoras que se pueden constatar en las demás jurisdicciones provinciales.

[^12]: Nueva gestión judicial : oralidad en los procesos civiles, Héctor M. Chayer ... [et al.] ; coordinación general de Héctor M. Chayer ; Juan Pablo Marcet. - 2a ed ampliada. Ciudad Autónoma de Buenos Aires : Ediciones SAIJ, 2017.

Por último, aunque el foco de nuestro trabajo está puesto en documentos judiciales, no es difícil advertir que el grueso de la administración pública ( y buena parte de la privada) funciona con el soporte de documentos administrativos no estucturados o semi-estructurados. Por eso, los avances en el procesamiento de documentos judiciales presentan un gran potencial de transferencia hacia otros dominios de la administración en general, multiplicando los beneficios sociales y contribuyendo al bienestar de nuestra comunidad [@samy2021].

## Estado del arte

-   @samy2021 pto.2 .

-   Aspectos vacantes? enfoque transversal para la tarea NER, que ataque el problema a gran escala [@samy2021]

Teniendo en cuenta la detallada reseña elaborada por @roy2021 sobre la tarea NER en general, vamos a centrarnos en los avances generados respecto de aplicaciones al ámbito legal. En lenguas distintas al español, podemos mencionar a @leitner2019 que proponen aplicar dos modelos basados en *campos aleatorios condicionales* (*Conditional Random Fields* o CRFs) y *redes neuronales recurrentes de memoria de corto y largo plazo* (BLSTM) a un corpus creado y anotado ad-hoc de textos legales en alemán. La tipología de clases empleada en el estudio incluyó 19[^13] categorías que pueden consultarse en su idioma original.[^14] Para esas dos arquitecturas se probaron tres modelos, obteniendo los mejores resultados con BiLSTM (F1 95.4/95.9). Por su parte @chalkidis2021 realizan detallados experimentos, que incluyeron optimización de hiperparámetros, para distintos modelos de redes neuronales recurrentes: LSTMs, DILATED-CNNs, TRANSFORMER y BERT. Reportan los mejores resultados con el primer modelo y el empleo de representaciones distribuidas de de palabras específica del dominio (*word embedings* mediante algoritmo *wor2vec*) sobre el uso de representaciones genéricas (GLOVE).

[^13]: Que podrían traducirse como: persona, juez/a, abogado/a, país, ciudad, calle, paisaje, organización, empresa, institución, Corte, marca, ley, ordenanza, Norma Legal de la Comunidad Europea, regulación, contrato, decisión judicial y bibliografía legal.

[^14]: <https://github.com/elenanereiss/Legal-Entity-Recognition>

Otras implementaciónes vinculadas al dominio encontramos en @pais2021 que plantean una arquitectura basada en redes neuronales recurrentes BLSTM y una capa final CRF, como imputs emplean representaciones de palabras, caracteres embebidos (*character* *embedings), diccionarios* y afijos en idioma Rumano*.* Como dato interesante, estos evalúan ensambles de modelos y logran los mejores resultados de los experimentos (F1 90.36). Por su parte @cardellino2017 proponen un trabajo dirigido no solo a la tarea de renocimiento y clasificación de entidades sino también su vinculación a una ontología (LKIF-Wikipedia)[^15], reportando resultados en torno a F1 80% para distintos niveles de granularidad. La arquitectura experimentada en este trabajo incluyó a Máquinas de Soporte Vectorial (SVM), redes neuronales (NN) y redes entrenadas sobre imputs basados en representación vectorial (*word-embedings)*. Finalmente, otros proyectos interesantes atacan problemas específicos en la tarea NER: @barriere2019 proponen un modelo MICA (*May I Check Again*) para resolver typos y errores de escritura en entidades mediante la generación contextualizada de candidatos; @skylaki2020 aborda la terea NER en documentos PDF con pérdida de información (*noisy text*) empleando una estrategia que no implica anotación sino la generación de entidades en el texto, entre otros.

[^15]: Tarea que en el ámbito legal es particularmente necesaria dadas las relaciones fuertemente estructuradas y jerarquías que predominan en este dominio, aunque su realización implica un alto costo en tiempo y recursos para desarrollarse y mantenerse.

Dentro de los pocos trabajos actuales aplicados al español legal vamos a encontrar a @samy2021

trabajo de tesis Haag con direccion de Cordellino.

## Desafíos

[texto DavidPerezFernandez]

No obstante, los trabajos en esta área se enfrentan con retos como: 1) El número limitado de recursos y herramientas de PLN adaptados al dominio en general; 2) La predominancia del inglés, ya que la mayoría de los recursos y las herramientas disponibles se desarrollan para el tratamiento de textos en inglés; 3) Una adopción ralentizada de las tecnologías inteligentes en el sector legal y administrativo en comparación con otros sectores como el sector biomédico o financiero. Estos retos han influido en que la consolidación de la tarea NERC en el dominio legal ha tardado unos años en comparación con otros dominios. De ahí, el presente estudio pretende afrontar la tarea en los textos legales españoles teniendo como objetivo principal el reconocimiento y la clasificación de cinco tipos básicos de entidades nombradas en textos legislativos españoles.

Legal language is unique and differs greatly from newspaper language. This also relates to the use of person, location and organization NEs in legal text, which are relatively rare. It does contain such specific entities as designations of legal norms and references to other legal documents (laws, ordinances, regulations, decisions, etc.) that play an essential role. @leitner_fine-grained_2019

Despite the development of NER for other languages and domains, the legal domain has not been exhaustively addressed yet. This research also had to face the following two challenges. (1) There is no uniform typology of semantic concepts related to NEs in documents from the legal domain; correspondingly, uniform annotation guidelines for NEs in the legal domain do not exist either. (2) There are no freely available datasets consisting of documents from the legal domain, in which NEs have been annotated. Thus, the research goal is to examine NER with a specific focus on German legal documents. This includes the elaboration of the corresponding concepts, the construction of a dataset, developing, evaluating and comparing state of the art models for NER. @leitner_fine-grained_2019

Se han probado los componente NER de librerías spaCy y Stanza con resultados no satisfactorios [@samy2021]

Todo ello sin mencionar las exigentes condiciones legales y reglamentarias que regulan la disposición y tratamiento de bases de datos judiciales, entre la que están: Protección de datos personales, datos sensibles, .....

# Metodología

baseline (ver \@ Francesca L)

Ver @samy2021

PreAnotación

-   Tipología de categorías semanticas acorde al dominio.

-   expresiones regulares: ej. fechas

-   listas: leyes, organismos, lugares (países, comunidades autónomas, provincias y localidades, tipos de vía, etc. Para utilizar estas listas, fue necesario un proceso de depuración porque presentaban los mismos problemas señalados anteriormente. Además, se ha optado por excluir algunos nombres de localidades por su ambigüedad y por el posible ruido que puede causar en forma de falsos positivos. Por ejemplo, se han eliminado de la lista localidades como "María", "Javier" o "Caso".)

-   nombres propios (SGP), cargos y puestos

Entrenamiento de Modelo

Para tener una referencia con la que comparar el rendimiento de sistemas de aprendizaje autom atico complejos, como las arquitecturas neuronales descriptas arriba, se decidio utilizar como modelo base la misma arquitectura mostrada en la Figura 3, pero con la diferencia que los modelos internos ahora est an basados en M aquinas de vectores soporte (SVM por sus siglas en ingles). Las maquinas de vectores soporte son una familia de algoritmos de aprendizaje supervisado, donde la idea principal del algoritmo es que a partir de los datos de entrenamiento se intenta encontrar un hiperplano optimo que maximice el margen (Maximal Margin Classifier ). El margen se define como la distancia entre el hiperplano de separaci on (lımite de decision) y las muestras de entrenamiento de cada una de las clases que se quieren separar m as cercanas a este hiperplano, que son los llamados vectores de soporte.

\-\-\-\-\-\-\-\--Adem as se desarrollar a un aprendedor automatico simple *baseline*. Este aprendedor, a comparacion de las tecnicas de aprendizaje profundo, no requiere mucha experiencia ni tiempo para su construcci on y posee menos par ametros que las redes neuronales, que generalmente en arquitecturas complejas tienen una gran cantidad de par ametros. Este servira como referencia para los demas aprendedores.

## Área de Estudio

@samy2021

El reconocimiento de entidades nombradas (NER por sus siglas en ingles), tambien conocido como extracci on de entidades, es una tarea de extracci on de informaci on que busca localizar y clasificar en categorıas predefinidas como personas, organizaciones, lugares, expresiones de tiempo y cantidades, las entidades nombradas encontradas en un texto. El reconocimiento de entidades nombradas a menudo se divide conceptualmente en dos problemas distintos: detecci on de nombres, y clasificaci on de los nombres seg un el tipo de entidad al que hacen referencia. Es por eso que muchas veces en la literatura se lo conoce como reconocimiento y clasificaci on de entidades nombradas (NERC por sus siglas en ingles). Una tercera fase que se desprende del reconocimiento y clasificaci on de entidades nombradas se conoce como anotaci on semantica (entity linking en ingles) donde se anota una entidad con una referencia a alg un link de una base de conocimiento que contenga una definici on sem antica de la entidad (Carreras et al., 2003). La primera fase generalmente se reduce a un problema de segmentaci on: los nombres son una secuencia contigua de tokens, sin solapamiento ni anidamiento, de modo que Banco de la Nacion Argentina es un nombre unico, a pesar del hecho de que dentro de este nombre aparezca la subcadena Argentina que es a su vez el nombre de un paıs. La segunda fase se trata de asignar una categorıa, de entre un conjunto predeterminado, a cada una de las entidades previamente reconocidas en la fase uno. El reconocimiento y clasificaci on de entidades nombradas se puede aprovechar de varias maneras, incluyendo el suministro de enlaces de hipertexto a la informaci on almacenada sobre por ejemplo un artıculo en particular. Por ejemplo, una menci on del "Banco de la Naci on Argentina" podrıa resolverse en un link a la pagina de Wikipedia que contenga un artıculo sobre esta entidad.

## Obtención y preparación de datos

## Procesamiento de datos

To adapt categories for the legal domain, the set of NE classes was redefined in the approaches described above. Thus, Dozier et al. [13] focused on legal NEs (e.g., judge, lawyer, court ). Cardellino et al. [8] extended NEs on NERC level to document, abstraction,andact. It is unclear what belongs to these classes and how they were separated from each other. Glaser et al. [18] added reference [23]. However, this was understood as a reference to legal norms, so that further references (to decisions, regulations, legal literature, etc.) were not covered. @leitner_fine-grained_2019

3.1 Semantic Categories Legal documents differ from texts in other domains, and from each other in terms of text-internal, and text-external criteria [7,12,15,21], which has a huge impact on linguistic and thematic design, citation, structure, etc. This also applies to NEs used in legal documents. In law texts and administrative regulations, the occurrence of typical NEs such as person, location and organization is very low. Court decisions, on the other hand, include these NEs, and references to national or supranational laws, other decisions, and regulations. Two requirements for a typology of legal NEs emerge from these peculiarities. First, the categories used must reflect those entities that are typical for decisions. Second, a typology must concern the entities whose differentiation in decisions is highly relevant. @leitner_fine-grained_2019 [275]

Taxonomía de las categorías: 19! ver @leitner_fine-grained_2019

Ojo con la anonimización de sentencias debido a protección de datos personals.

## Entrenamiento de modelos

@gutiérrez-fandiño2021

## Evaluación

# Software

El trabajo se desarrollará utilizando el lenguaje de programación Python 3 y frameworks o librerías asociadas. .... Para el entrenamiento y evaluación de los modelos de NLP propuestos se utilizarán las plataformas Google Colab y Kaggle las cuales brindan acceso gratuito a GPU's de alto rendimiento.

# Cronograma

\pagebreak
